Microsoft Windows [Version 10.0.26100.4351]
(c) Microsoft Corporation. All rights reserved.

(env) E:\Master Projects\MLFlow-in-Claim-Injury-Prediction>kedro run --pipeline=complete_pipeline
[06/24/25 03:14:27] INFO     Using 'conf\logging.yml' as logging configuration. You can change this by setting the KEDRO_LOGGING_CONFIG environment variable accordingly.                                        __init__.py:270
                    WARNING  E:\Master Projects\MLFlow-in-Claim-Injury-Prediction\env\Lib\site-packages\kedro\io\data_catalog.py:165: KedroDeprecationWarning: `DataCatalog` has been deprecated and will be     warnings.py:110
                             replaced by `KedroDataCatalog`, in Kedro 1.0.0.Currently some `KedroDataCatalog` APIs have been retained for compatibility with `DataCatalog`, including the `datasets` property                   
                             and the `get_datasets`, `_get_datasets`, `add`,` list`, `add_feed_dict`, and `shallow_copy` methods. These will be removed or replaced with updated alternatives in Kedro 1.0.0.                   
                             For more details, refer to the documentation: https://docs.kedro.org/en/stable/data/index.html#kedrodatacatalog-experimental-feature                                                               
                               warnings.warn(                                                                                                                                                                                   
                                                                                                                                                                                                                                
[06/24/25 03:14:28] WARNING  E:\Master Projects\MLFlow-in-Claim-Injury-Prediction\env\Lib\site-packages\kedro\io\data_catalog.py:165: KedroDeprecationWarning: `DataCatalog` has been deprecated and will be     warnings.py:110
                             replaced by `KedroDataCatalog`, in Kedro 1.0.0.Currently some `KedroDataCatalog` APIs have been retained for compatibility with `DataCatalog`, including the `datasets` property                   
                             and the `get_datasets`, `_get_datasets`, `add`,` list`, `add_feed_dict`, and `shallow_copy` methods. These will be removed or replaced with updated alternatives in Kedro 1.0.0.                   
                             For more details, refer to the documentation: https://docs.kedro.org/en/stable/data/index.html#kedrodatacatalog-experimental-feature                                                               
                               warnings.warn(                                                                                                                                                                                                    
                                                                                                                                                                                                                                                 
                    INFO     Kedro project MLFlow-in-Claim-Injury-Prediction                                                                                                                                      session.py:329                 
[06/24/25 03:14:32] WARNING  E:\Master Projects\MLFlow-in-Claim-Injury-Prediction\env\Lib\site-packages\pydantic\_internal\_config.py:323: PydanticDeprecatedSince20: Support for class-based `config` is        warnings.py:110                 
                             deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/                                               
                               warnings.warn(DEPRECATION_MESSAGE, DeprecationWarning)                                                                                                                                                            
                                                                                                                                                                                                                                                 
                    WARNING  E:\Master Projects\MLFlow-in-Claim-Injury-Prediction\env\Lib\site-packages\geopandas\_compat.py:7: DeprecationWarning: The 'shapely.geos' module is deprecated, and will be removed warnings.py:110                 
                             in a future version. All attributes of 'shapely.geos' are available directly from the top-level 'shapely' namespace (since shapely 2.0.0).                                                                          
                               import shapely.geos                                                                                                                                                                                               
                                                                                                                                                                                                                                                 
[06/24/25 03:14:33] WARNING  KedroDeprecationWarning: `DataCatalog` has been deprecated and will be replaced by `KedroDataCatalog`, in Kedro 1.0.0.Currently some `KedroDataCatalog` APIs have been retained for warnings.py:110                 
                             compatibility with `DataCatalog`, including the `datasets` property and the `get_datasets`, `_get_datasets`, `add`,` list`, `add_feed_dict`, and `shallow_copy` methods. These will                                 
                             be removed or replaced with updated alternatives in Kedro 1.0.0. For more details, refer to the documentation:                                                                                                      
                             https://docs.kedro.org/en/stable/data/index.html#kedrodatacatalog-experimental-feature                                                                                                                              
                                                                                                                                                                                                                                                 
                    INFO     Kedro is sending anonymous usage data with the sole purpose of improving the product. No personal data or IP addresses are stored on our side. If you want to opt out, set the        plugin.py:233                 
                             `KEDRO_DISABLE_TELEMETRY` or `DO_NOT_TRACK` environment variables, or create a `.telemetry` file in the current working directory with the contents `consent: false`. Read more at                                  
                             https://docs.kedro.org/en/stable/configuration/telemetry.html                                                                                                                                                       
                    INFO     Using synchronous mode for loading and saving data. Use the --async flag for potential performance gains.                                                                   sequential_runner.py:68                 
                             https://docs.kedro.org/en/stable/nodes_and_pipelines/run_a_pipeline.html#load-and-save-asynchronously                                                                                                               
                    INFO     Loading data from raw_input_data (CSVDataset)...                                                                                                                                data_catalog.py:401                 
[06/24/25 03:14:35] INFO     Loading data from params:raw_datasource_name (MemoryDataset)...                                                                                                                                  data_catalog.py:401
                    INFO     Loading data from params:raw_suite_name (MemoryDataset)...                                                                                                                                       data_catalog.py:401
                    INFO     Loading data from params:raw_data_asset_name (MemoryDataset)...                                                                                                                                  data_catalog.py:401
                    INFO     Loading data from params:build_data_docs (MemoryDataset)...                                                                                                                                      data_catalog.py:401
                    INFO     Running node: validate_raw_data_node: test_data() ->                                                                                                                                                     node.py:367
Calculating Metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 1983.44it/s]
[06/24/25 03:14:36] INFO     Initial data validation passed for asset: train_data                                                                                                                                                     nodes.py:64
                    INFO     Saving data to raw_data_validated (CSVDataset)...                                                                                                                                                data_catalog.py:443
[06/24/25 03:14:41] INFO     Completed node: validate_raw_data_node                                                                                                                                                                 runner.py:244
                    INFO     Completed 1 out of 15 tasks                                                                                                                                                                            runner.py:245
                    INFO     Loading data from raw_data_validated (CSVDataset)...                                                                                                                                             data_catalog.py:401
[06/24/25 03:14:43] INFO     Running node: preprocess_raw_data_node: preprocess_raw_data() ->                                                                                                                                         node.py:367
                    INFO     Preprocessing raw data. Input shape: (593471, 33)                                                                                                                                                        nodes.py:20
[06/24/25 03:14:44] INFO     Data preprocessing completed. Output shape: (593471, 32)                                                                                                                                                 nodes.py:56
                    INFO     Columns: ['accident_date', 'age_at_injury', 'alternative_dispute_resolution', 'assembly_date', 'attorney/representative', 'average_weekly_wage', 'birth_year', 'c-2_date', 'c-3_date', 'carrier_name',   nodes.py:57
                             'carrier_type', 'claim_identifier', 'claim_injury_type', 'county_of_injury', 'covid-19_indicator', 'district_name', 'first_hearing_date', 'gender', 'ime-4_count', 'industry_code',                                 
                             'industry_code_description', 'medical_fee_region', 'wcio_cause_of_injury_code', 'wcio_cause_of_injury_description', 'wcio_nature_of_injury_code', 'wcio_nature_of_injury_description',                              
                             'wcio_part_of_body_code', 'wcio_part_of_body_description', 'zip_code', 'agreement_reached', 'wcb_decision', 'number_of_dependents']                                                                                 
                    INFO     Saving data to processed_data (CSVDataset)...                                                                                                                                                    data_catalog.py:443
[06/24/25 03:14:51] INFO     Completed node: preprocess_raw_data_node                                                                                                                                                               runner.py:244
                    INFO     Completed 2 out of 15 tasks                                                                                                                                                                            runner.py:245
                    INFO     Loading data from processed_data (CSVDataset)...                                                                                                                                                 data_catalog.py:401
[06/24/25 03:14:52] INFO     Loading data from params:target_column (MemoryDataset)...                                                                                                                                        data_catalog.py:401
                    INFO     Running node: prepare_data_for_splitting: prepare_data_for_splitting() ->                                                                                                                                node.py:367
                    INFO     Preparing data for splitting. Shape: (593471, 32)                                                                                                                                                        nodes.py:22
                    INFO     Found target column: 'claim_injury_type'                                                                                                                                                                 nodes.py:42
[06/24/25 03:14:53] INFO     Data prepared successfully. Final shape: (593471, 31)                                                                                                                                                    nodes.py:61
                    INFO     Target column: claim_injury_type                                                                                                                                                                         nodes.py:62
                    INFO     Available columns: ['accident_date', 'age_at_injury', 'alternative_dispute_resolution', 'assembly_date', 'attorney/representative', 'average_weekly_wage', 'birth_year', 'c-2_date', 'c-3_date',         nodes.py:63
                             'carrier_name', 'carrier_type', 'claim_identifier', 'claim_injury_type', 'covid-19_indicator', 'district_name', 'first_hearing_date', 'gender', 'ime-4_count', 'industry_code',                                     
                             'industry_code_description', 'medical_fee_region', 'wcio_cause_of_injury_code', 'wcio_cause_of_injury_description', 'wcio_nature_of_injury_code', 'wcio_nature_of_injury_description',                              
                             'wcio_part_of_body_code', 'wcio_part_of_body_description', 'zip_code', 'agreement_reached', 'wcb_decision', 'number_of_dependents']                                                                                 
                    INFO     Saving data to processed_data_validated_final (CSVDataset)...                                                                                                                                    data_catalog.py:443
[06/24/25 03:14:58] INFO     Completed node: prepare_data_for_splitting                                                                                                                                                             runner.py:244
                    INFO     Completed 3 out of 15 tasks                                                                                                                                                                            runner.py:245
                    INFO     Loading data from processed_data (CSVDataset)...                                                                                                                                                 data_catalog.py:401
[06/24/25 03:14:59] INFO     Loading data from params:feature_store (MemoryDataset)...                                                                                                                                        data_catalog.py:401
                    INFO     Loading data from params:feature_groups_config (MemoryDataset)...                                                                                                                                data_catalog.py:401
                    INFO     Running node: robust_feature_groups_with_gx: create_feature_groups_with_gx_robust() ->                                                                                                                   node.py:367
                    INFO     === Robust Feature Groups Creation with Great Expectations ===                                                                                                                                          nodes.py:270
                    INFO     Original data shape: (593471, 32)                                                                                                                                                                       nodes.py:271
[06/24/25 03:15:00] INFO     Mapped 0 column names for feature store compatibility                                                                                                                                                   nodes.py:133
                    WARNING  Unmapped columns: ['accident_date', 'age_at_injury', 'alternative_dispute_resolution', 'assembly_date', 'attorney/representative', 'average_weekly_wage', 'birth_year', 'c-2_date', 'c-3_date',         nodes.py:139
                             'carrier_name', 'carrier_type', 'claim_identifier', 'claim_injury_type', 'county_of_injury', 'covid-19_indicator', 'district_name', 'first_hearing_date', 'gender', 'ime-4_count', 'industry_code',                 
                             'industry_code_description', 'medical_fee_region', 'wcio_cause_of_injury_code', 'wcio_cause_of_injury_description', 'wcio_nature_of_injury_code', 'wcio_nature_of_injury_description',                              
                             'wcio_part_of_body_code', 'wcio_part_of_body_description', 'zip_code', 'agreement_reached', 'wcb_decision', 'number_of_dependents']                                                                                 
                    INFO     Data type conversion completed for feature store compatibility                                                                                                                                          nodes.py:248
                    INFO     Data shape after column mapping: (593471, 32)                                                                                                                                                           nodes.py:275
                    INFO     ‚úÖ Successfully connected to existing Great Expectations setup                                                                                                                                          nodes.py:282

Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225911
[06/24/25 03:15:03] INFO     üìã Could not list existing feature groups - will create all                                                                                                                                             nodes.py:305
                    INFO     üìã Found 0 existing feature groups                                                                                                                                                                      nodes.py:308
                    INFO     üîÑ Creating feature group: personal_information                                                                                                                                                         nodes.py:403
                    INFO        Available columns: ['age_at_injury', 'birth_year']                                                                                                                                                   nodes.py:404
                    INFO        Data shape: (593471, 4)                                                                                                                                                                              nodes.py:412
                    INFO        üîç Validating data with Great Expectations...                                                                                                                                                        nodes.py:418
                    INFO     Using existing expectation suite: personal_information_expectations                                                                                                                        feature_store_utils.py:42
                    ERROR    Validation failed for personal_information_expectations: Cannot initialize datasource pandas_datasource, error: The given datasource could not be retrieved from the DataContext; please   feature_store_utils.py:92
                             confirm that your configuration is accurate.                                                                                                                                                                        
                    WARNING     ‚ö†Ô∏è  Data validation failed for personal_information, but proceeding...                                                                                                                                nodes.py:4221
                    INFO        üì§ Attempt 1/3                                                                                                                                                                                       nodes.py:433
[06/24/25 03:15:04] INFO        üì¶ Large dataset detected. Uploading in chunks of 50,000                                                                                                                                             nodes.py:499
                    INFO        üì¶ Uploading 593,471 rows in 12 chunks                                                                                                                                                               nodes.py:509
                    INFO        üì§ Uploading chunk 1/12 (50,000 rows)                                                                                                                                                                nodes.py:515
                    ERROR       ‚ùå Failed to upload chunk 1: Features are not compatible with Feature Group schema:                                                                                                                  nodes.py:531
                              - gender_m (type: 'bigint') is missing from input dataframe.                                                                                                                                                       
                              - birth_year (type: 'double') does not exist in feature group.                                                                                                                                                     
                             Note that feature (or column) names are case insensitive and spaces are automatically replaced with underscores.                                                                                                    
                    WARNING     ‚ö†Ô∏è  Attempt 1 failed: Data upload failed                                                                                                                                                              nodes.py:484
                    INFO        ‚è≥ Waiting 30 seconds before retry...                                                                                                                                                                nodes.py:487
[06/24/25 03:15:34] INFO        üì§ Attempt 2/3                                                                                                                                                                                       nodes.py:433
                    INFO        üì¶ Large dataset detected. Uploading in chunks of 50,000                                                                                                                                             nodes.py:499
                    INFO        üì¶ Uploading 593,471 rows in 12 chunks                                                                                                                                                               nodes.py:509
                    INFO        üì§ Uploading chunk 1/12 (50,000 rows)                                                                                                                                                                nodes.py:515
                    ERROR       ‚ùå Failed to upload chunk 1: Features are not compatible with Feature Group schema:                                                                                                                  nodes.py:531
                              - gender_m (type: 'bigint') is missing from input dataframe.                                                                                                                                                       
                              - birth_year (type: 'double') does not exist in feature group.                                                                                                                                                     
                             Note that feature (or column) names are case insensitive and spaces are automatically replaced with underscores.                                                                                                    
                    WARNING     ‚ö†Ô∏è  Attempt 2 failed: Data upload failed                                                                                                                                                              nodes.py:484
                    INFO        ‚è≥ Waiting 60 seconds before retry...                                                                                                                                                                nodes.py:487
[06/24/25 03:16:34] INFO        üì§ Attempt 3/3                                                                                                                                                                                       nodes.py:433
                    INFO        üì¶ Large dataset detected. Uploading in chunks of 50,000                                                                                                                                             nodes.py:499
                    INFO        üì¶ Uploading 593,471 rows in 12 chunks                                                                                                                                                               nodes.py:509
                    INFO        üì§ Uploading chunk 1/12 (50,000 rows)                                                                                                                                                                nodes.py:515
                    ERROR       ‚ùå Failed to upload chunk 1: Features are not compatible with Feature Group schema:                                                                                                                  nodes.py:531
                              - gender_m (type: 'bigint') is missing from input dataframe.                                                                                                                                                       
                              - birth_year (type: 'double') does not exist in feature group.                                                                                                                                                     
                             Note that feature (or column) names are case insensitive and spaces are automatically replaced with underscores.                                                                                                    
                    WARNING     ‚ö†Ô∏è  Attempt 3 failed: Data upload failed                                                                                                                                                              nodes.py:484
                    ERROR    ‚ùå Failed to create: personal_information - All 3 attempts failed. Last error: Data upload failed                                                                                                       nodes.py:360
                    INFO     üîÑ Creating feature group: financial_features                                                                                                                                                           nodes.py:403
                    INFO        Available columns: ['average_weekly_wage', 'number_of_dependents']                                                                                                                                   nodes.py:404
                    INFO        Data shape: (593471, 4)                                                                                                                                                                              nodes.py:412
                    INFO        üîç Validating data with Great Expectations...                                                                                                                                                        nodes.py:418
                    INFO     Using existing expectation suite: financial_features_expectations                                                                                                                          feature_store_utils.py:42
                    ERROR    Validation failed for financial_features_expectations: Cannot initialize datasource pandas_datasource, error: The given datasource could not be retrieved from the DataContext; please     feature_store_utils.py:92
                             confirm that your configuration is accurate.                                                                                                                                                                        
                    WARNING     ‚ö†Ô∏è  Data validation failed for financial_features, but proceeding...                                                                                                                                  nodes.py:421
                    INFO        üì§ Attempt 1/3                                                                                                                                                                                       nodes.py:433
[06/24/25 03:16:35] INFO        üì¶ Large dataset detected. Uploading in chunks of 50,000                                                                                                                                             nodes.py:499
                    INFO        üì¶ Uploading 593,471 rows in 12 chunks                                                                                                                                                               nodes.py:509
                    INFO        üì§ Uploading chunk 1/12 (50,000 rows)                                                                                                                                                                nodes.py:515
                    ERROR       ‚ùå Failed to upload chunk 1: Features are not compatible with Feature Group schema:                                                                                                                  nodes.py:531
                              - number_of_dependents (type: 'double') does not exist in feature group.                                                                                                                                           
                             Note that feature (or column) names are case insensitive and spaces are automatically replaced with underscores.                                                                                                    
                    WARNING     ‚ö†Ô∏è  Attempt 1 failed: Data upload failed                                                                                                                                                              nodes.py:484
                    INFO        ‚è≥ Waiting 30 seconds before retry...                                                                                                                                                                nodes.py:487





[06/24/25 03:17:05] INFO        üì§ Attempt 2/3                                                                                                                                                                                       nodes.py:433
                    INFO        üì¶ Large dataset detected. Uploading in chunks of 50,000                                                                                                                                             nodes.py:499
                    INFO        üì¶ Uploading 593,471 rows in 12 chunks                                                                                                                                                               nodes.py:509
                    INFO        üì§ Uploading chunk 1/12 (50,000 rows)                                                                                                                                                                nodes.py:515
                    ERROR       ‚ùå Failed to upload chunk 1: Features are not compatible with Feature Group schema:                                                                                                                  nodes.py:531
                              - number_of_dependents (type: 'double') does not exist in feature group.                                                                                                                                           
                             Note that feature (or column) names are case insensitive and spaces are automatically replaced with underscores.                                                                                                    
                    WARNING     ‚ö†Ô∏è  Attempt 2 failed: Data upload failed                                                                                                                                                              nodes.py:4884
                    INFO        ‚è≥ Waiting 60 seconds before retry...                                                                                                                                                                nodes.py:487
[06/24/25 03:18:05] INFO        üì§ Attempt 3/3                                                                                                                                                                                       nodes.py:433
[06/24/25 03:18:06] INFO        üì¶ Large dataset detected. Uploading in chunks of 50,000                                                                                                                                             nodes.py:499
                    INFO        üì¶ Uploading 593,471 rows in 12 chunks                                                                                                                                                               nodes.py:509
                    INFO        üì§ Uploading chunk 1/12 (50,000 rows)                                                                                                                                                                nodes.py:515
                    ERROR       ‚ùå Failed to upload chunk 1: Features are not compatible with Feature Group schema:                                                                                                                  nodes.py:531
                              - number_of_dependents (type: 'double') does not exist in feature group.                                                                                                                                           
                             Note that feature (or column) names are case insensitive and spaces are automatically replaced with underscores.                                                                                                    
                    WARNING     ‚ö†Ô∏è  Attempt 3 failed: Data upload failed                                                                                                                                                              nodes.py:4884
                    ERROR    ‚ùå Failed to create: financial_features - All 3 attempts failed. Last error: Data upload failed                                                                                                         nodes.py:360
                    WARNING  ‚è≠Ô∏è  Skipping medical_case_processing - no columns available                                                                                                                                              nodes.py:3337
                    INFO     üîÑ Creating feature group: geographic_administrative                                                                                                                                                    nodes.py:403
                    INFO        Available columns: ['county_of_injury', 'district_name', 'zip_code']                                                                                                                                 nodes.py:404
                    INFO        Data shape: (593471, 5)                                                                                                                                                                              nodes.py:412
                    INFO        üîç Validating data with Great Expectations...                                                                                                                                                        nodes.py:418
                    INFO     Using existing expectation suite: geographic_administrative_expectations                                                                                                                   feature_store_utils.py:42
                    ERROR    Validation failed for geographic_administrative_expectations: Cannot initialize datasource pandas_datasource, error: The given datasource could not be retrieved from the DataContext;     feature_store_utils.py:92
                             please confirm that your configuration is accurate.                                                                                                                                                                 
                    WARNING     ‚ö†Ô∏è  Data validation failed for geographic_administrative, but proceeding...                                                                                                                           nodes.py:4221
                    INFO        üì§ Attempt 1/3                                                                                                                                                                                       nodes.py:433
                    INFO        üì¶ Large dataset detected. Uploading in chunks of 50,000                                                                                                                                             nodes.py:499
                    INFO        üì¶ Uploading 593,471 rows in 12 chunks                                                                                                                                                               nodes.py:509
                    INFO        üì§ Uploading chunk 1/12 (50,000 rows)                                                                                                                                                                nodes.py:515
                    ERROR       ‚ùå Failed to upload chunk 1: Features are not compatible with Feature Group schema:                                                                                                                  nodes.py:531
                              - zip_code (type: 'string') does not exist in feature group.                                                                                                                                                       
                             Note that feature (or column) names are case insensitive and spaces are automatically replaced with underscores.                                                                                                    
                    WARNING     ‚ö†Ô∏è  Attempt 1 failed: Data upload failed                                                                                                                                                              nodes.py:4884
                    INFO        ‚è≥ Waiting 30 seconds before retry...                                                                                                                                                                nodes.py:487
[06/24/25 03:18:36] INFO        üì§ Attempt 2/3                                                                                                                                                                                       nodes.py:433
[06/24/25 03:18:37] INFO        üì¶ Large dataset detected. Uploading in chunks of 50,000                                                                                                                                             nodes.py:499
                    INFO        üì¶ Uploading 593,471 rows in 12 chunks                                                                                                                                                               nodes.py:509
                    INFO        üì§ Uploading chunk 1/12 (50,000 rows)                                                                                                                                                                nodes.py:515
                    ERROR       ‚ùå Failed to upload chunk 1: Features are not compatible with Feature Group schema:                                                                                                                  nodes.py:531
                              - zip_code (type: 'string') does not exist in feature group.                                                                                                                                                       
                             Note that feature (or column) names are case insensitive and spaces are automatically replaced with underscores.                                                                                                    
                    WARNING     ‚ö†Ô∏è  Attempt 2 failed: Data upload failed                                                                                                                                                              nodes.py:4884
                    INFO        ‚è≥ Waiting 60 seconds before retry...                                                                                                                                                                nodes.py:487
[06/24/25 03:19:37] INFO        üì§ Attempt 3/3                                                                                                                                                                                       nodes.py:433
                    INFO        üì¶ Large dataset detected. Uploading in chunks of 50,000                                                                                                                                             nodes.py:499
                    INFO        üì¶ Uploading 593,471 rows in 12 chunks                                                                                                                                                               nodes.py:509
                    INFO        üì§ Uploading chunk 1/12 (50,000 rows)                                                                                                                                                                nodes.py:515
                    ERROR       ‚ùå Failed to upload chunk 1: Features are not compatible with Feature Group schema:                                                                                                                  nodes.py:531
                              - zip_code (type: 'string') does not exist in feature group.                                                                                                                                                       
                             Note that feature (or column) names are case insensitive and spaces are automatically replaced with underscores.                                                                                                    
                    WARNING     ‚ö†Ô∏è  Attempt 3 failed: Data upload failed                                                                                                                                                              nodes.py:4884
                    ERROR    ‚ùå Failed to create: geographic_administrative - All 3 attempts failed. Last error: Data upload failed                                                                                                  nodes.py:360
                    INFO     üîÑ Creating feature group: injury_industry_classification                                                                                                                                               nodes.py:403
                    INFO        Available columns: ['wcio_nature_of_injury_code', 'industry_code', 'wcio_cause_of_injury_code', 'wcio_part_of_body_code']                                                                            nodes.py:404
                    INFO        Data shape: (593471, 6)                                                                                                                                                                              nodes.py:412
                    INFO        üîç Validating data with Great Expectations...                                                                                                                                                        nodes.py:418
                    INFO     Using existing expectation suite: injury_industry_classification_expectations                                                                                                              feature_store_utils.py:42
                    ERROR    Validation failed for injury_industry_classification_expectations: Cannot initialize datasource pandas_datasource, error: The given datasource could not be retrieved from the             feature_store_utils.py:92
                             DataContext; please confirm that your configuration is accurate.                                                                                                                                                    
                    WARNING     ‚ö†Ô∏è  Data validation failed for injury_industry_classification, but proceeding...                                                                                                                      nodes.py:4221
                    INFO        üì§ Attempt 1/3                                                                                                                                                                                       nodes.py:433
[06/24/25 03:19:38] INFO        üì¶ Large dataset detected. Uploading in chunks of 50,000                                                                                                                                             nodes.py:499
                    INFO        üì¶ Uploading 593,471 rows in 12 chunks                                                                                                                                                               nodes.py:509
                    INFO        üì§ Uploading chunk 1/12 (50,000 rows)                                                                                                                                                                nodes.py:515
                    ERROR       ‚ùå Failed to upload chunk 1: Features are not compatible with Feature Group schema:                                                                                                                  nodes.py:531
                              - wcio_nature_of_injury_code (expected type: 'double', derived from input: 'string') has the wrong type.                                                                                                           
                              - industry_code (expected type: 'double', derived from input: 'string') has the wrong type.                                                                                                                        
                              - wcio_cause_of_injury_code (expected type: 'double', derived from input: 'string') has the wrong type.                                                                                                            
                              - wcio_part_of_body_code (expected type: 'double', derived from input: 'string') has the wrong type.                                                                                                               
                             Note that feature (or column) names are case insensitive and spaces are automatically replaced with underscores.                                                                                                    
                    WARNING     ‚ö†Ô∏è  Attempt 1 failed: Data upload failed                                                                                                                                                              nodes.py:4884
                    INFO        ‚è≥ Waiting 30 seconds before retry...                                                                                                                                                                nodes.py:487
[06/24/25 03:20:08] INFO        üì§ Attempt 2/3                                                                                                                                                                                       nodes.py:433
                    INFO        üì¶ Large dataset detected. Uploading in chunks of 50,000                                                                                                                                             nodes.py:499
                    INFO        üì¶ Uploading 593,471 rows in 12 chunks                                                                                                                                                               nodes.py:509
                    INFO        üì§ Uploading chunk 1/12 (50,000 rows)                                                                                                                                                                nodes.py:515
                    ERROR       ‚ùå Failed to upload chunk 1: Features are not compatible with Feature Group schema:                                                                                                                  nodes.py:531
                              - wcio_nature_of_injury_code (expected type: 'double', derived from input: 'string') has the wrong type.                                                                                                           
                              - industry_code (expected type: 'double', derived from input: 'string') has the wrong type.                                                                                                                        
                              - wcio_cause_of_injury_code (expected type: 'double', derived from input: 'string') has the wrong type.                                                                                                            
                              - wcio_part_of_body_code (expected type: 'double', derived from input: 'string') has the wrong type.                                                                                                               
                             Note that feature (or column) names are case insensitive and spaces are automatically replaced with underscores.                                                                                                    
                    WARNING     ‚ö†Ô∏è  Attempt 2 failed: Data upload failed                                                                                                                                                              nodes.py:4884
                    INFO        ‚è≥ Waiting 60 seconds before retry...                                                                                                                                                                nodes.py:487
[06/24/25 03:21:08] INFO        üì§ Attempt 3/3                                                                                                                                                                                       nodes.py:433
[06/24/25 03:21:09] INFO        üì¶ Large dataset detected. Uploading in chunks of 50,000                                                                                                                                             nodes.py:499
                    INFO        üì¶ Uploading 593,471 rows in 12 chunks                                                                                                                                                               nodes.py:509
                    INFO        üì§ Uploading chunk 1/12 (50,000 rows)                                                                                                                                                                nodes.py:515
                    ERROR       ‚ùå Failed to upload chunk 1: Features are not compatible with Feature Group schema:                                                                                                                  nodes.py:531
                              - wcio_nature_of_injury_code (expected type: 'double', derived from input: 'string') has the wrong type.                                                                                                           
                              - industry_code (expected type: 'double', derived from input: 'string') has the wrong type.                                                                                                                        
                              - wcio_cause_of_injury_code (expected type: 'double', derived from input: 'string') has the wrong type.                                                                                                            
                              - wcio_part_of_body_code (expected type: 'double', derived from input: 'string') has the wrong type.                                                                                                               
                             Note that feature (or column) names are case insensitive and spaces are automatically replaced with underscores.                                                                                                    
                    WARNING     ‚ö†Ô∏è  Attempt 3 failed: Data upload failed                                                                                                                                                              nodes.py:4884
                    ERROR    ‚ùå Failed to create: injury_industry_classification - All 3 attempts failed. Last error: Data upload failed                                                                                             nodes.py:360
                    WARNING  ‚è≠Ô∏è  Skipping medical_fee_regions - no columns available                                                                                                                                                  nodes.py:3337
                    WARNING  ‚è≠Ô∏è  Skipping special_indicators - no columns available                                                                                                                                                   nodes.py:3337
                    WARNING  ‚è≠Ô∏è  Skipping seasonal_features - no columns available                                                                                                                                                    nodes.py:3337
                    INFO     === SUMMARY ===                                                                                                                                                                                         nodes.py:378
                    INFO     ‚úÖ Created: 0 feature groups                                                                                                                                                                            nodes.py:379
                    INFO     ‚ùå Failed: 4 feature groups                                                                                                                                                                             nodes.py:380
                    INFO     ‚è≠Ô∏è  Skipped: 4 feature groups                                                                                                                                                                            nodes.py:3881
                    INFO     üîç Used Great Expectations: True                                                                                                                                                                        nodes.py:382
                    INFO     Saving data to feature_groups_metadata (JSONDataset)...                                                                                                                                          data_catalog.py:443
                    INFO     Completed node: robust_feature_groups_with_gx                                                                                                                                                          runner.py:244
                    INFO     Completed 4 out of 15 tasks                                                                                                                                                                            runner.py:245
                    INFO     Loading data from processed_data (CSVDataset)...                                                                                                                                                 data_catalog.py:401
[06/24/25 03:21:10] INFO     Loading data from params:group_name (MemoryDataset)...                                                                                                                                           data_catalog.py:401
                    INFO     Loading data from params:description (MemoryDataset)...                                                                                                                                          data_catalog.py:401
                    INFO     Loading data from params:feature_descriptions (MemoryDataset)...                                                                                                                                 data_catalog.py:401
                    INFO     Loading data from params:suite_name (MemoryDataset)...                                                                                                                                           data_catalog.py:401
                    INFO     Running node: upload_data: upload_data() -> None                                                                                                                                                         node.py:367
Connection closed.

Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225911
[06/24/25 03:21:21] ERROR    Node upload_data: upload_data() -> None failed with error:                                                                                                                                               node.py:392
                             Expected bytes, got a 'float' object                                                                                                                                                                                
                    WARNING  There are 11 nodes that have not run.                                                                                                                                                                  runner.py:338
                             You can resume the pipeline run from the nearest nodes with persisted inputs by adding the following argument to your previous command:                                                                             
                               --from-nodes "split_data_node,upload_data,validate_feature_store_setup"                                                                                                                                           
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Traceback (most recent call last) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ in _run_module_as_main:198                                                                       ‚îÇ
‚îÇ in _run_code:88                                                                                  ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ in <module>:7                                                                                    ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ E:\Master                                                                                        ‚îÇ
‚îÇ Projects\MLFlow-in-Claim-Injury-Prediction\env\Lib\site-packages\kedro\framework\cli\cli.py:263  ‚îÇ
‚îÇ in main                                                                                          ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ   260 ‚îÇ   cli_collection = KedroCLI(                                                             ‚îÇ
‚îÇ   261 ‚îÇ   ‚îÇ   project_path=_find_kedro_project(Path.cwd()) or Path.cwd()                         ‚îÇ
‚îÇ   262 ‚îÇ   )                                                                                      ‚îÇ
‚îÇ ‚ù± 263 ‚îÇ   cli_collection()                                                                       ‚îÇ
‚îÇ   264                                                                                            ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ E:\Master Projects\MLFlow-in-Claim-Injury-Prediction\env\Lib\site-packages\click\core.py:1442 in ‚îÇ
‚îÇ __call__                                                                                         ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ E:\Master                                                                                        ‚îÇ
‚îÇ Projects\MLFlow-in-Claim-Injury-Prediction\env\Lib\site-packages\kedro\framework\cli\cli.py:163  ‚îÇ
‚îÇ in main                                                                                          ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ   160 ‚îÇ   ‚îÇ   )                                                                                  ‚îÇ
‚îÇ   161 ‚îÇ   ‚îÇ                                                                                      ‚îÇ
‚îÇ   162 ‚îÇ   ‚îÇ   try:                                                                               ‚îÇ
‚îÇ ‚ù± 163 ‚îÇ   ‚îÇ   ‚îÇ   super().main(                                                                  ‚îÇ
‚îÇ   164 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   args=args,                                                                 ‚îÇ
‚îÇ   165 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   prog_name=prog_name,                                                       ‚îÇ
‚îÇ   166 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   complete_var=complete_var,                                                 ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ E:\Master Projects\MLFlow-in-Claim-Injury-Prediction\env\Lib\site-packages\click\core.py:1363 in ‚îÇ
‚îÇ main                                                                                             ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ E:\Master Projects\MLFlow-in-Claim-Injury-Prediction\env\Lib\site-packages\click\core.py:1830 in ‚îÇ
‚îÇ invoke                                                                                           ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ E:\Master Projects\MLFlow-in-Claim-Injury-Prediction\env\Lib\site-packages\click\core.py:1226 in ‚îÇ
‚îÇ invoke                                                                                           ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ E:\Master Projects\MLFlow-in-Claim-Injury-Prediction\env\Lib\site-packages\click\core.py:794 in  ‚îÇ
‚îÇ invoke                                                                                           ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ E:\Master                                                                                        ‚îÇ
‚îÇ Projects\MLFlow-in-Claim-Injury-Prediction\env\Lib\site-packages\kedro\framework\cli\project.py: ‚îÇ
‚îÇ 229 in run                                                                                       ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ   226 ‚îÇ   with KedroSession.create(                                                              ‚îÇ
‚îÇ   227 ‚îÇ   ‚îÇ   env=env, conf_source=conf_source, extra_params=params                              ‚îÇ
‚îÇ   228 ‚îÇ   ) as session:                                                                          ‚îÇ
‚îÇ ‚ù± 229 ‚îÇ   ‚îÇ   return session.run(                                                                ‚îÇ
‚îÇ   230 ‚îÇ   ‚îÇ   ‚îÇ   tags=tuple_tags,                                                               ‚îÇ
‚îÇ   231 ‚îÇ   ‚îÇ   ‚îÇ   runner=runner_obj(is_async=is_async),                                          ‚îÇ
‚îÇ   232 ‚îÇ   ‚îÇ   ‚îÇ   node_names=tuple_node_names,                                                   ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ E:\Master                                                                                        ‚îÇ
‚îÇ Projects\MLFlow-in-Claim-Injury-Prediction\env\Lib\site-packages\kedro\framework\session\session ‚îÇ
‚îÇ .py:399 in run                                                                                   ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ   396 ‚îÇ   ‚îÇ   ‚îÇ   run_params=record_data, pipeline=filtered_pipeline, catalog=catalog            ‚îÇ
‚îÇ   397 ‚îÇ   ‚îÇ   )                                                                                  ‚îÇ
‚îÇ   398 ‚îÇ   ‚îÇ   try:                                                                               ‚îÇ
‚îÇ ‚ù± 399 ‚îÇ   ‚îÇ   ‚îÇ   run_result = runner.run(                                                       ‚îÇ
‚îÇ   400 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   filtered_pipeline, catalog, hook_manager, session_id                       ‚îÇ
‚îÇ   401 ‚îÇ   ‚îÇ   ‚îÇ   )                                                                              ‚îÇ
‚îÇ   402 ‚îÇ   ‚îÇ   ‚îÇ   self._run_called = True                                                        ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ E:\Master                                                                                        ‚îÇ
‚îÇ Projects\MLFlow-in-Claim-Injury-Prediction\env\Lib\site-packages\kedro\runner\runner.py:129 in   ‚îÇ
‚îÇ run                                                                                              ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ   126 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   "Asynchronous mode is enabled for loading and saving data"                 ‚îÇ
‚îÇ   127 ‚îÇ   ‚îÇ   ‚îÇ   )                                                                              ‚îÇ
‚îÇ   128 ‚îÇ   ‚îÇ                                                                                      ‚îÇ
‚îÇ ‚ù± 129 ‚îÇ   ‚îÇ   self._run(pipeline, catalog, hook_or_null_manager, session_id)  # type: ignore[a   ‚îÇ
‚îÇ   130 ‚îÇ   ‚îÇ                                                                                      ‚îÇ
‚îÇ   131 ‚îÇ   ‚îÇ   self._logger.info("Pipeline execution completed successfully.")                    ‚îÇ
‚îÇ   132                                                                                            ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ E:\Master                                                                                        ‚îÇ
‚îÇ Projects\MLFlow-in-Claim-Injury-Prediction\env\Lib\site-packages\kedro\runner\sequential_runner. ‚îÇ
‚îÇ py:72 in _run                                                                                    ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ   69 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   "Using synchronous mode for loading and saving data. Use the --async fla    ‚îÇ
‚îÇ   70 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   "for potential performance gains. https://docs.kedro.org/en/stable/nodes    ‚îÇ
‚îÇ   71 ‚îÇ   ‚îÇ   ‚îÇ   )                                                                               ‚îÇ
‚îÇ ‚ù± 72 ‚îÇ   ‚îÇ   super()._run(                                                                       ‚îÇ
‚îÇ   73 ‚îÇ   ‚îÇ   ‚îÇ   pipeline=pipeline,                                                              ‚îÇ
‚îÇ   74 ‚îÇ   ‚îÇ   ‚îÇ   catalog=catalog,                                                                ‚îÇ
‚îÇ   75 ‚îÇ   ‚îÇ   ‚îÇ   hook_manager=hook_manager,                                                      ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ E:\Master                                                                                        ‚îÇ
‚îÇ Projects\MLFlow-in-Claim-Injury-Prediction\env\Lib\site-packages\kedro\runner\runner.py:239 in   ‚îÇ
‚îÇ _run                                                                                             ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ   236 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   hook_manager=hook_manager,                                         ‚îÇ
‚îÇ   237 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   is_async=self._is_async,                                           ‚îÇ
‚îÇ   238 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   session_id=session_id,                                             ‚îÇ
‚îÇ ‚ù± 239 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ).execute()                                                            ‚îÇ
‚îÇ   240 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   done_nodes.add(node)                                                   ‚îÇ
‚îÇ   241 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   except Exception:                                                          ‚îÇ
‚îÇ   242 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   self._suggest_resume_scenario(pipeline, done_nodes, catalog)           ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ E:\Master                                                                                        ‚îÇ
‚îÇ Projects\MLFlow-in-Claim-Injury-Prediction\env\Lib\site-packages\kedro\runner\task.py:88 in      ‚îÇ
‚îÇ execute                                                                                          ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ    85 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   self.session_id,                                                           ‚îÇ
‚îÇ    86 ‚îÇ   ‚îÇ   ‚îÇ   )                                                                              ‚îÇ
‚îÇ    87 ‚îÇ   ‚îÇ   else:                                                                              ‚îÇ
‚îÇ ‚ù±  88 ‚îÇ   ‚îÇ   ‚îÇ   node = self._run_node_sequential(                                              ‚îÇ
‚îÇ    89 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   self.node,                                                                 ‚îÇ
‚îÇ    90 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   self.catalog,                                                              ‚îÇ
‚îÇ    91 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   self.hook_manager,  # type: ignore[arg-type]                               ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ E:\Master                                                                                        ‚îÇ
‚îÇ Projects\MLFlow-in-Claim-Injury-Prediction\env\Lib\site-packages\kedro\runner\task.py:164 in     ‚îÇ
‚îÇ _run_node_sequential                                                                             ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ   161 ‚îÇ   ‚îÇ   )                                                                                  ‚îÇ
‚îÇ   162 ‚îÇ   ‚îÇ   inputs.update(additional_inputs)                                                   ‚îÇ
‚îÇ   163 ‚îÇ   ‚îÇ                                                                                      ‚îÇ
‚îÇ ‚ù± 164 ‚îÇ   ‚îÇ   outputs = self._call_node_run(                                                     ‚îÇ
‚îÇ   165 ‚îÇ   ‚îÇ   ‚îÇ   node, catalog, inputs, is_async, hook_manager, session_id=session_id           ‚îÇ
‚îÇ   166 ‚îÇ   ‚îÇ   )                                                                                  ‚îÇ
‚îÇ   167                                                                                            ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ E:\Master                                                                                        ‚îÇ
‚îÇ Projects\MLFlow-in-Claim-Injury-Prediction\env\Lib\site-packages\kedro\runner\task.py:308 in     ‚îÇ
‚îÇ _call_node_run                                                                                   ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ   305 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   is_async=is_async,                                                         ‚îÇ
‚îÇ   306 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   session_id=session_id,                                                     ‚îÇ
‚îÇ   307 ‚îÇ   ‚îÇ   ‚îÇ   )                                                                              ‚îÇ
‚îÇ ‚ù± 308 ‚îÇ   ‚îÇ   ‚îÇ   raise exc                                                                      ‚îÇ
‚îÇ   309 ‚îÇ   ‚îÇ   hook_manager.hook.after_node_run(                                                  ‚îÇ
‚îÇ   310 ‚îÇ   ‚îÇ   ‚îÇ   node=node,                                                                     ‚îÇ
‚îÇ   311 ‚îÇ   ‚îÇ   ‚îÇ   catalog=catalog,                                                               ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ E:\Master                                                                                        ‚îÇ
‚îÇ Projects\MLFlow-in-Claim-Injury-Prediction\env\Lib\site-packages\kedro\runner\task.py:298 in     ‚îÇ
‚îÇ _call_node_run                                                                                   ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ   295 ‚îÇ   ‚îÇ   session_id: str | None = None,                                                     ‚îÇ
‚îÇ   296 ‚îÇ   ) -> dict[str, Any]:                                                                   ‚îÇ
‚îÇ   297 ‚îÇ   ‚îÇ   try:                                                                               ‚îÇ
‚îÇ ‚ù± 298 ‚îÇ   ‚îÇ   ‚îÇ   outputs = node.run(inputs)                                                     ‚îÇ
‚îÇ   299 ‚îÇ   ‚îÇ   except Exception as exc:                                                           ‚îÇ
‚îÇ   300 ‚îÇ   ‚îÇ   ‚îÇ   hook_manager.hook.on_node_error(                                               ‚îÇ
‚îÇ   301 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   error=exc,                                                                 ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ E:\Master                                                                                        ‚îÇ
‚îÇ Projects\MLFlow-in-Claim-Injury-Prediction\env\Lib\site-packages\kedro\pipeline\node.py:398 in   ‚îÇ
‚îÇ run                                                                                              ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ   395 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   str(exc),                                                                  ‚îÇ
‚îÇ   396 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   extra={"markup": True},                                                    ‚îÇ
‚îÇ   397 ‚îÇ   ‚îÇ   ‚îÇ   )                                                                              ‚îÇ
‚îÇ ‚ù± 398 ‚îÇ   ‚îÇ   ‚îÇ   raise exc                                                                      ‚îÇ
‚îÇ   399 ‚îÇ                                                                                          ‚îÇ
‚îÇ   400 ‚îÇ   def _run_with_no_inputs(self, inputs: dict[str, Any]) -> Any:                          ‚îÇ
‚îÇ   401 ‚îÇ   ‚îÇ   if inputs:                                                                         ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ E:\Master                                                                                        ‚îÇ
‚îÇ Projects\MLFlow-in-Claim-Injury-Prediction\env\Lib\site-packages\kedro\pipeline\node.py:384 in   ‚îÇ
‚îÇ run                                                                                              ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ   381 ‚îÇ   ‚îÇ   ‚îÇ   elif isinstance(self._inputs, str):                                            ‚îÇ
‚îÇ   382 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   outputs = self._run_with_one_input(inputs, self._inputs)                   ‚îÇ
‚îÇ   383 ‚îÇ   ‚îÇ   ‚îÇ   elif isinstance(self._inputs, list):                                           ‚îÇ
‚îÇ ‚ù± 384 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   outputs = self._run_with_list(inputs, self._inputs)                        ‚îÇ
‚îÇ   385 ‚îÇ   ‚îÇ   ‚îÇ   elif isinstance(self._inputs, dict):                                           ‚îÇ
‚îÇ   386 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   outputs = self._run_with_dict(inputs, self._inputs)                        ‚îÇ
‚îÇ   387                                                                                            ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ E:\Master                                                                                        ‚îÇ
‚îÇ Projects\MLFlow-in-Claim-Injury-Prediction\env\Lib\site-packages\kedro\pipeline\node.py:429 in   ‚îÇ
‚îÇ _run_with_list                                                                                   ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ   426 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   f"{sorted(inputs.keys())}."                                                ‚îÇ
‚îÇ   427 ‚îÇ   ‚îÇ   ‚îÇ   )                                                                              ‚îÇ
‚îÇ   428 ‚îÇ   ‚îÇ   # Ensure the function gets the inputs in the correct order                         ‚îÇ
‚îÇ ‚ù± 429 ‚îÇ   ‚îÇ   return self._func(*(inputs[item] for item in node_inputs))                         ‚îÇ
‚îÇ   430 ‚îÇ                                                                                          ‚îÇ
‚îÇ   431 ‚îÇ   def _run_with_dict(                                                                    ‚îÇ
‚îÇ   432 ‚îÇ   ‚îÇ   self, inputs: dict[str, Any], node_inputs: dict[str, str]                          ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ E:\Master                                                                                        ‚îÇ
‚îÇ Projects\MLFlow-in-Claim-Injury-Prediction\src\mlflow_in_claim_injury_prediction\pipelines\data_ ‚îÇ
‚îÇ upload\nodes.py:39 in upload_data                                                                ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ   36 ‚îÇ   settings_store = read_credentials()["SETTINGS_STORE"]                                   ‚îÇ
‚îÇ   37 ‚îÇ   suite = load_expectation_suite(suite_name)                                              ‚îÇ
‚îÇ   38 ‚îÇ                                                                                           ‚îÇ
‚îÇ ‚ù± 39 ‚îÇ   to_feature_store(                                                                       ‚îÇ
‚îÇ   40 ‚îÇ   ‚îÇ   data=df,                                                                            ‚îÇ
‚îÇ   41 ‚îÇ   ‚îÇ   group_name=group_name,                                                              ‚îÇ
‚îÇ   42 ‚îÇ   ‚îÇ   feature_group_version=1,                                                            ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ E:\Master                                                                                        ‚îÇ
‚îÇ Projects\MLFlow-in-Claim-Injury-Prediction\src\mlflow_in_claim_injury_prediction\pipelines\data_ ‚îÇ
‚îÇ upload\utils.py:108 in to_feature_store                                                          ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ   105 ‚îÇ   # Upload data.                                                                         ‚îÇ
‚îÇ   106 ‚îÇ   # NOTE: The overwrite parameter is set to False to avoid overwriting the data.         ‚îÇ
‚îÇ   107 ‚îÇ   # instead, the data is appended to the feature group.                                  ‚îÇ
‚îÇ ‚ù± 108 ‚îÇ   object_feature_group.insert(                                                           ‚îÇ
‚îÇ   109 ‚îÇ   ‚îÇ   features=data,                                                                     ‚îÇ
‚îÇ   110 ‚îÇ   ‚îÇ   overwrite=False,                                                                   ‚îÇ
‚îÇ   111 ‚îÇ   ‚îÇ   write_options={                                                                    ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ E:\Master                                                                                        ‚îÇ
‚îÇ Projects\MLFlow-in-Claim-Injury-Prediction\env\Lib\site-packages\hsfs\feature_group.py:3014 in   ‚îÇ
‚îÇ insert                                                                                           ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ   3011 ‚îÇ   ‚îÇ   if not self._id and self._offline_backfill_every_hr is not None:                  ‚îÇ
‚îÇ   3012 ‚îÇ   ‚îÇ   ‚îÇ   write_options["offline_backfill_every_hr"] = self._offline_backfill_every_hr  ‚îÇ
‚îÇ   3013 ‚îÇ   ‚îÇ                                                                                     ‚îÇ
‚îÇ ‚ù± 3014 ‚îÇ   ‚îÇ   job, ge_report = self._feature_group_engine.insert(                               ‚îÇ
‚îÇ   3015 ‚îÇ   ‚îÇ   ‚îÇ   self,                                                                         ‚îÇ
‚îÇ   3016 ‚îÇ   ‚îÇ   ‚îÇ   feature_dataframe=feature_dataframe,                                          ‚îÇ
‚îÇ   3017 ‚îÇ   ‚îÇ   ‚îÇ   overwrite=overwrite,                                                          ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ E:\Master                                                                                        ‚îÇ
‚îÇ Projects\MLFlow-in-Claim-Injury-Prediction\env\Lib\site-packages\hsfs\core\feature_group_engine. ‚îÇ
‚îÇ py:153 in insert                                                                                 ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ   150 ‚îÇ   ‚îÇ   transformation_context: Dict[str, Any] = None,                                     ‚îÇ
‚îÇ   151 ‚îÇ   ‚îÇ   transform: bool = True,                                                            ‚îÇ
‚îÇ   152 ‚îÇ   ):                                                                                     ‚îÇ
‚îÇ ‚ù± 153 ‚îÇ   ‚îÇ   dataframe_features = engine.get_instance().parse_schema_feature_group(             ‚îÇ
‚îÇ   154 ‚îÇ   ‚îÇ   ‚îÇ   feature_dataframe,                                                             ‚îÇ
‚îÇ   155 ‚îÇ   ‚îÇ   ‚îÇ   feature_group.time_travel_format,                                              ‚îÇ
‚îÇ   156 ‚îÇ   ‚îÇ   ‚îÇ   features=feature_group.features,                                               ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ E:\Master                                                                                        ‚îÇ
‚îÇ Projects\MLFlow-in-Claim-Injury-Prediction\env\Lib\site-packages\hsfs\engine\python.py:769 in    ‚îÇ
‚îÇ parse_schema_feature_group                                                                       ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ    766 ‚îÇ   ‚îÇ   ‚îÇ   for _feature in features:                                                     ‚îÇ
‚îÇ    767 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   feature_type_map[_feature.name] = _feature.type                           ‚îÇ
‚îÇ    768 ‚îÇ   ‚îÇ   if isinstance(dataframe, pd.DataFrame):                                           ‚îÇ
‚îÇ ‚ù±  769 ‚îÇ   ‚îÇ   ‚îÇ   arrow_schema = pa.Schema.from_pandas(dataframe, preserve_index=False)         ‚îÇ
‚îÇ    770 ‚îÇ   ‚îÇ   elif (                                                                            ‚îÇ
‚îÇ    771 ‚îÇ   ‚îÇ   ‚îÇ   HAS_POLARS                                                                    ‚îÇ
‚îÇ    772 ‚îÇ   ‚îÇ   ‚îÇ   and isinstance(dataframe, pl.DataFrame)                                       ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ in pyarrow.lib.Schema.from_pandas:3225                                                           ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ E:\Master                                                                                        ‚îÇ
‚îÇ Projects\MLFlow-in-Claim-Injury-Prediction\env\Lib\site-packages\pyarrow\pandas_compat.py:575 in ‚îÇ
‚îÇ dataframe_to_types                                                                               ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ    572 ‚îÇ   ‚îÇ   ‚îÇ   values, type_ = get_datetimetz_type(values, c.dtype, None)                    ‚îÇ
‚îÇ    573 ‚îÇ   ‚îÇ   ‚îÇ   type_ = pa.lib._ndarray_to_arrow_type(values, type_)                          ‚îÇ
‚îÇ    574 ‚îÇ   ‚îÇ   ‚îÇ   if type_ is None:                                                             ‚îÇ
‚îÇ ‚ù±  575 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   type_ = pa.array(c, from_pandas=True).type                                ‚îÇ
‚îÇ    576 ‚îÇ   ‚îÇ   types.append(type_)                                                               ‚îÇ
‚îÇ    577 ‚îÇ                                                                                         ‚îÇ
‚îÇ    578 ‚îÇ   metadata = construct_metadata(                                                        ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ in pyarrow.lib.array:362                                                                         ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ in pyarrow.lib._ndarray_to_array:87                                                              ‚îÇ
‚îÇ                                                                                                  ‚îÇ
‚îÇ in pyarrow.lib.check_status:92                                                                   ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
ArrowTypeError: Expected bytes, got a 'float' object
Connection closed.